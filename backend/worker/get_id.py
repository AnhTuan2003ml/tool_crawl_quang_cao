import requests
import json
import re
import codecs
from urllib.parse import urlencode, urlparse, parse_qs

# ====== L∆ØU √ù ======
# Cookies v√† payload ƒë∆∞·ª£c l·∫•y t·ª´ cookies.json v√† payload.txt th√¥ng qua profile_id
# cookies.json c√≥ c·∫•u tr√∫c: {"profile_id": {"cookie": "...", "access_token": "..."}}
# S·ª≠ d·ª•ng get_payload.get_payload_by_profile_id(profile_id) ƒë·ªÉ l·∫•y payload
# S·ª≠ d·ª•ng get_payload.get_cookies_by_profile_id(profile_id) ƒë·ªÉ l·∫•y cookie


def _import_get_cookies_by_profile_id():
    """
    H·ªó tr·ª£ ch·∫°y ƒë∆∞·ª£c c·∫£ 2 ki·ªÉu:
    - ch·∫°y tr·ª±c ti·∫øp trong folder backend/worker (import get_payload)
    - ch·∫°y qua module backend.worker.get_id (import backend.worker.get_payload)
    """
    try:
        from get_payload import get_cookies_by_profile_id  # type: ignore
        return get_cookies_by_profile_id
    except Exception:
        try:
            from backend.worker.get_payload import get_cookies_by_profile_id  # type: ignore
            return get_cookies_by_profile_id
        except Exception:
            # fallback (n·∫øu sys.path ƒë√£ append worker_path)
            from worker.get_payload import get_cookies_by_profile_id  # type: ignore
            return get_cookies_by_profile_id


# ================================
#   H√ÄM G·ªåI API V·ªöI URL VIDEO
# ================================
def get_post_id(video_url, profile_id, cookies=None):
    """
    L·∫•y post_id v√† owning_profile t·ª´ HTML source (view-source)
    S·ª≠ d·ª•ng cookies ƒë·ªÉ m·ªü nh∆∞ tr√¨nh duy·ªát b√¨nh th∆∞·ªùng
    
    Args:
        video_url (str): URL c·ªßa video Facebook (v√≠ d·ª•: "https://www.facebook.com/reel/1525194028720314/")
        profile_id (str): Profile ID ƒë·ªÉ l·∫•y cookies
        cookies (str, optional): Cookie string (n·∫øu ƒë√£ c√≥ s·∫µn)
        
    Returns:
        tuple: (post_id, owning_profile_dict) ho·∫∑c (None, None) n·∫øu kh√¥ng t√¨m th·∫•y
        owning_profile_dict: {"__typename": "...", "name": "...", "id": "..."} ho·∫∑c None
    """
    # S·ª≠ d·ª•ng HTML source ƒë·ªÉ l·∫•y th√¥ng tin (v·ªõi cookies)
    # B√¢y gi·ªù h√†m n·ªôi b·ªô tr·∫£ th√™m final_url ƒë·ªÉ ki·ªÉm tra reel
    post_id, owning_profile, post_text, final_url = get_post_id_from_html(video_url, profile_id, cookies)
    
    # Decode Unicode escape sequences trong owning_profile name n·∫øu c√≥
    if owning_profile and "name" in owning_profile:
        name = owning_profile['name']
        if isinstance(name, str) and '\\u' in name:
            try:
                name = json.loads(f'"{name}"')
                owning_profile['name'] = name
            except:
                try:
                    name = codecs.decode(name, 'unicode_escape')
                    owning_profile['name'] = name
                except:
                    pass
    
    return post_id, owning_profile, post_text, final_url


def get_post_id_from_html(url, profile_id, cookies=None):
    """
    L·∫•y post_id v√† owning_profile t·ª´ HTML source c·ªßa trang (view-source)
    S·ª≠ d·ª•ng cookies ƒë·ªÉ m·ªü nh∆∞ tr√¨nh duy·ªát b√¨nh th∆∞·ªùng
    
    Args:
        url (str): URL c·ªßa Facebook post
        profile_id (str): Profile ID ƒë·ªÉ l·∫•y cookies
        cookies (str, optional): Cookie string (n·∫øu ƒë√£ c√≥ s·∫µn)
        
    Returns:
        tuple: (post_id, owning_profile_dict) ho·∫∑c (None, None) n·∫øu kh√¥ng t√¨m th·∫•y
        owning_profile_dict: {"__typename": "...", "name": "...", "id": "..."} ho·∫∑c None
    """
    get_cookies_by_profile_id = _import_get_cookies_by_profile_id()
    
    # L·∫•y cookies n·∫øu ch∆∞a c√≥
    if cookies is None:
        cookies = get_cookies_by_profile_id(profile_id)
        if not cookies:
            print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y cookies t·ª´ profile_id: {profile_id}")
            return None, None
    
    try:
        # T·∫°o session ƒë·ªÉ qu·∫£n l√Ω cookies t·ªët h∆°n (nh∆∞ tr√¨nh duy·ªát)
        session = requests.Session()
        
        # Parse cookies string th√†nh dict v√† th√™m v√†o session
        # Cookies string format: "name1=value1; name2=value2; ..."
        if cookies:
            cookies_dict = {}
            for cookie_pair in cookies.split(';'):
                cookie_pair = cookie_pair.strip()
                if '=' in cookie_pair:
                    key, value = cookie_pair.split('=', 1)
                    cookies_dict[key.strip()] = value.strip()
            session.cookies.update(cookies_dict)
        
        # Headers cho GET request (gi·ªëng tr√¨nh duy·ªát, CH·ªà gzip/deflate ƒë·ªÉ tr√°nh l·ªói brotli tr√™n m√°y thi·∫øu th∆∞ vi·ªán)
        get_headers = {
            "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "accept-encoding": "gzip, deflate",
            "accept-language": "en,vi;q=0.9,en-US;q=0.8",
            "referer": "https://www.facebook.com/",
            "sec-ch-ua": '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "same-origin",
            "upgrade-insecure-requests": "1",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"
        }
        
        # L·∫•y HTML source tr·ª±c ti·∫øp (view-source) v·ªõi cookies
        print(f"üåê L·∫•y HTML source (view-source) tr·ª±c ti·∫øp t·ª´: {url}")
        response = session.get(url, headers=get_headers)
        
        print(f"üìä Status Code: {response.status_code}")
        print(f"üìÑ Response Length: {len(response.text)} characters")
        
        if response.status_code != 200:
            print(f"‚ùå Status code kh√¥ng ph·∫£i 200: {response.status_code}")
            return None, None
        
        html_content = response.text
        print(f"‚úÖ ƒê√£ l·∫•y HTML content ({len(html_content)} k√Ω t·ª±)")
        # final_url (sau redirect n·∫øu c√≥)
        final_url = getattr(response, "url", "") or url
        print(f"üîÅ Final URL sau request: {final_url}")
        
        # Debug: T√¨m c√°c pattern c√≥ th·ªÉ c√≥ trong HTML
        # Facebook c√≥ th·ªÉ escape ho·∫∑c encode kh√°c
        print(f"\nüîç ƒêang t√¨m ki·∫øm patterns...")
        
        # Th·ª≠ t√¨m post_id v·ªõi nhi·ªÅu pattern kh√°c nhau
        post_id = None
        
        # Pattern 1: "post_id":"123456789" (chu·∫©n)
        match = re.search(r'"post_id"\s*:\s*"(\d+)"', html_content)
        if match:
            post_id = match.group(1)
            print(f"‚úÖ T√¨m th·∫•y post_id (pattern 1): {post_id}")
        else:
            # Pattern 2: "post_id":123456789 (kh√¥ng c√≥ quotes)
            match = re.search(r'"post_id"\s*:\s*(\d+)', html_content)
            if match:
                post_id = match.group(1)
                print(f"‚úÖ T√¨m th·∫•y post_id (pattern 2): {post_id}")
            else:
                # Pattern 3: post_id":"123456789" (c√≥ th·ªÉ escape)
                match = re.search(r'post_id["\']?\s*:\s*["\']?(\d+)', html_content)
                if match:
                    post_id = match.group(1)
                    print(f"‚úÖ T√¨m th·∫•y post_id (pattern 3): {post_id}")
                else:
                    # Pattern 4: T√¨m trong JSON structure
                    # C√≥ th·ªÉ l√† JSON ƒë∆∞·ª£c embed trong HTML
                    json_matches = re.findall(r'["\']post_id["\']\s*:\s*["\']?(\d+)', html_content, re.IGNORECASE)
                    if json_matches:
                        post_id = json_matches[0]
                        print(f"‚úÖ T√¨m th·∫•y post_id (pattern 4 - JSON): {post_id}")
                    else:
                        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y post_id v·ªõi b·∫•t k·ª≥ pattern n√†o")
                        # Debug: T√¨m m·ªôt s·ªë pattern kh√°c ƒë·ªÉ xem HTML c√≥ g√¨
                        if '"post_id"' in html_content:
                            print(f"   üîç T√¨m th·∫•y chu·ªói 'post_id' trong HTML nh∆∞ng kh√¥ng match pattern")
                            # T√¨m context xung quanh
                            idx = html_content.find('"post_id"')
                            if idx != -1:
                                context = html_content[max(0, idx-50):min(len(html_content), idx+100)]
                                print(f"   üìã Context: {context[:150]}...")
                        else:
                            print(f"   üîç Kh√¥ng t√¨m th·∫•y chu·ªói 'post_id' trong HTML")
        
        # ===== T√åM OWNING_PROFILE ƒê·∫¶U TI√äN TRONG HTML =====
        # Pattern: "owning_profile":{"__typename":"User","name":"...","id":"..."}
        # C√≥ th·ªÉ c√≥ c√°c field kh√°c nh∆∞ "short_name" gi·ªØa c√°c field
        owning_profile = None
        
        # T√¨m owning_profile v·ªõi nhi·ªÅu pattern kh√°c nhau
        
        # Pattern 1: "owning_profile":{ (chu·∫©n)
        pattern = r'"owning_profile"\s*:\s*\{'
        match = re.search(pattern, html_content)
        
        if match:
            print(f"‚úÖ T√¨m th·∫•y 'owning_profile':{{ t·∫°i v·ªã tr√≠ {match.start()}")
            start_pos = match.end()
            
            # T√¨m closing brace t∆∞∆°ng ·ª©ng (balanced braces)
            brace_count = 1
            end_pos = start_pos
            while end_pos < len(html_content) and brace_count > 0:
                if html_content[end_pos] == '{':
                    brace_count += 1
                elif html_content[end_pos] == '}':
                    brace_count -= 1
                end_pos += 1
            
            if brace_count == 0:
                # L·∫•y n·ªôi dung b√™n trong braces
                block_content = html_content[start_pos:end_pos-1]
                print(f"   üìã Block content length: {len(block_content)} characters")
                
                # T√¨m c√°c field trong block n√†y
                owning_profile_data = {}
                
                # T√¨m __typename
                typename_match = re.search(r'"__typename"\s*:\s*"([^"]+)"', block_content)
                if typename_match:
                    owning_profile_data["__typename"] = typename_match.group(1)
                    print(f"   ‚úÖ T√¨m th·∫•y __typename: {typename_match.group(1)}")
                
                # T√¨m name
                name_match = re.search(r'"name"\s*:\s*"([^"]+)"', block_content)
                if name_match:
                    owning_profile_data["name"] = name_match.group(1)
                    print(f"   ‚úÖ T√¨m th·∫•y name: {name_match.group(1)[:50]}...")
                
                # T√¨m id
                id_match = re.search(r'"id"\s*:\s*"([^"]+)"', block_content)
                if id_match:
                    owning_profile_data["id"] = id_match.group(1)
                    print(f"   ‚úÖ T√¨m th·∫•y id: {id_match.group(1)}")
                
                # Ch·ªâ l·∫•y n·∫øu c√≥ ƒë·ªß √≠t nh·∫•t 2 trong 3 fields (__typename, name, id)
                if len(owning_profile_data) >= 2:
                    owning_profile = owning_profile_data
                    print(f"‚úÖ ƒê√£ extract owning_profile th√†nh c√¥ng")
                else:
                    print(f"‚ö†Ô∏è Kh√¥ng ƒë·ªß fields trong owning_profile (ch·ªâ c√≥ {len(owning_profile_data)} fields)")
            else:
                print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y closing brace t∆∞∆°ng ·ª©ng (brace_count: {brace_count})")
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y pattern 'owning_profile':{{")
            # Debug: Ki·ªÉm tra xem c√≥ chu·ªói owning_profile kh√¥ng
            if '"owning_profile"' in html_content or "'owning_profile'" in html_content:
                print(f"   üîç T√¨m th·∫•y chu·ªói 'owning_profile' trong HTML nh∆∞ng kh√¥ng match pattern")
                # T√¨m context xung quanh
                idx = html_content.find('owning_profile')
                if idx != -1:
                    context = html_content[max(0, idx-50):min(len(html_content), idx+200)]
                    print(f"   üìã Context: {context[:200]}...")
            else:
                print(f"   üîç Kh√¥ng t√¨m th·∫•y chu·ªói 'owning_profile' trong HTML")
                # C√≥ th·ªÉ HTML ƒë∆∞·ª£c minify, th·ª≠ t√¨m trong JSON blocks
                # Facebook th∆∞·ªùng embed JSON trong script tags
                script_tags = re.findall(r'<script[^>]*>(.*?)</script>', html_content, re.DOTALL)
                print(f"   üîç T√¨m th·∫•y {len(script_tags)} script tags, ƒëang t√¨m trong ƒë√≥...")
                for i, script_content in enumerate(script_tags[:5]):  # Ch·ªâ check 5 script ƒë·∫ßu ti√™n
                    if 'owning_profile' in script_content:
                        print(f"   ‚úÖ T√¨m th·∫•y 'owning_profile' trong script tag #{i+1}")
                        # T√¨m trong script n√†y
                        match = re.search(r'"owning_profile"\s*:\s*\{', script_content)
                        if match:
                            print(f"      ‚úÖ Match pattern trong script tag!")
                            # Extract t·ª´ script content
                            start_pos = match.end()
                            brace_count = 1
                            end_pos = start_pos
                            while end_pos < len(script_content) and brace_count > 0:
                                if script_content[end_pos] == '{':
                                    brace_count += 1
                                elif script_content[end_pos] == '}':
                                    brace_count -= 1
                                end_pos += 1
                            
                            if brace_count == 0:
                                block_content = script_content[start_pos:end_pos-1]
                                owning_profile_data = {}
                                
                                typename_match = re.search(r'"__typename"\s*:\s*"([^"]+)"', block_content)
                                if typename_match:
                                    owning_profile_data["__typename"] = typename_match.group(1)
                                
                                name_match = re.search(r'"name"\s*:\s*"([^"]+)"', block_content)
                                if name_match:
                                    owning_profile_data["name"] = name_match.group(1)
                                
                                id_match = re.search(r'"id"\s*:\s*"([^"]+)"', block_content)
                                if id_match:
                                    owning_profile_data["id"] = id_match.group(1)
                                
                                if len(owning_profile_data) >= 2:
                                    owning_profile = owning_profile_data
                                    print(f"      ‚úÖ ƒê√£ extract owning_profile t·ª´ script tag!")
                                    break
        
        # Decode Unicode escape sequences trong owning_profile name n·∫øu c√≥
        if owning_profile and "name" in owning_profile:
            name = owning_profile['name']
            if isinstance(name, str) and '\\u' in name:
                try:
                    name = json.loads(f'"{name}"')
                    owning_profile['name'] = name
                except:
                    try:
                        name = codecs.decode(name, 'unicode_escape')
                        owning_profile['name'] = name
                    except:
                        pass

        # ===== L·∫§Y N·ªòI DUNG B√ÄI POST =====
        post_text = None

        # ∆Øu ti√™n l·∫•y n·ªôi dung trong block story_message (n·ªôi dung b√†i post)
        content_html = None

        story_match = re.search(
            r'data-ad-rendering-role="story_message"[^>]*>(.*?)</div></div></div>',
            html_content,
            re.DOTALL,
        )
        if story_match:
            content_html = story_match.group(1)
            print("‚úÖ T√¨m th·∫•y block story_message ƒë·ªÉ tr√≠ch n·ªôi dung b√†i post")
        else:
            # Fallback: d√πng m·ªôt ph·∫ßn ƒë·∫ßu HTML
            content_html = html_content[:500_000]
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y block story_message, d√πng fallback (500KB ƒë·∫ßu HTML)")

        # Thay <img ... alt="..."> b·∫±ng ch√≠nh alt (ƒë·ªÉ gi·ªØ emoji/text)
        def _img_alt_to_text(m):
            alt_text = m.group(1) or ""
            return f" {alt_text} "

        content_html = re.sub(
            r'<img[^>]*alt="([^"]*)"[^>]*>',
            _img_alt_to_text,
            content_html,
            flags=re.IGNORECASE,
        )

        # B·ªè to√†n b·ªô tag HTML c√≤n l·∫°i
        text_raw = re.sub(r"<[^>]*>", " ", content_html)
        # Chu·∫©n h√≥a kho·∫£ng tr·∫Øng
        text_clean = re.sub(r"\s+", " ", text_raw).strip()

        if text_clean:
            post_text = text_clean
            preview = post_text[:400] + "..." if len(post_text) > 400 else post_text
            print(f"‚úÖ Post text (preview): {preview}")
        else:
            print("‚ö†Ô∏è Kh√¥ng tr√≠ch ƒë∆∞·ª£c n·ªôi dung b√†i post t·ª´ HTML")

        # N·∫øu final_url ch·ª©a 'reel' => x·∫øp lo·∫°i reel: kh√¥ng l·∫•y post_text/owning_profile ƒë·∫ßy ƒë·ªß,
        # m√† ƒë·∫∑t owning_profile = {"__typename":"User","name": None, "id": "<actor_id>"} n·∫øu t√¨m ƒë∆∞·ª£c actor_id
        try:
            if "reel" in str(final_url).lower():
                print(f"üîî Final URL ch·ª©a 'reel' -> x·ª≠ l√Ω nh∆∞ reel/video: {final_url}")
                actor_id = None
                # T√¨m tr·ª±c ti·∫øp c√°c pattern actor_id trong HTML (kh√¥ng parse JSON)
                # 1) targets array scan (balanced) t√¨m "actor_id"
                try:
                    for m in re.finditer(r'"targets"\s*:', html_content):
                        idx = html_content.find('[', m.end())
                        if idx == -1:
                            continue
                        i = idx + 1
                        depth = 1
                        while i < len(html_content) and depth > 0:
                            if html_content[i] == '[':
                                depth += 1
                            elif html_content[i] == ']':
                                depth -= 1
                            i += 1
                        if depth != 0:
                            continue
                        array_text = html_content[idx:i]
                        mm = re.search(r'"actor_id"\s*:\s*["\']?(\d+)', array_text)
                        if mm:
                            actor_id = mm.group(1)
                            print(f"üîé T√¨m th·∫•y actor_id trong targets scan: {actor_id}")
                            break
                except Exception:
                    pass

                # 2) fallback: c√°c pattern kh√°c (content_owner_id_new, actor_id, actor.id)
                if not actor_id:
                    m = re.search(r'"content_owner_id_new"\s*:\s*"?(\\?\d+)"?', html_content)
                    if m:
                        actor_id = m.group(1).replace('\\', '')
                        print(f"üîé T√¨m th·∫•y actor_id t·ª´ content_owner_id_new: {actor_id}")
                if not actor_id:
                    m2 = re.search(r'"actor_id"\s*:\s*["\']?(\d+)', html_content)
                    if m2:
                        actor_id = m2.group(1)
                        print(f"üîé T√¨m th·∫•y actor_id b·∫±ng regex: {actor_id}")
                if not actor_id:
                    m3 = re.search(r'"actor"\s*:\s*\{\s*"id"\s*:\s*["\']?(\d+)', html_content)
                    if m3:
                        actor_id = m3.group(1)
                        print(f"üîé T√¨m th·∫•y actor.id b·∫±ng regex: {actor_id}")

                owning_profile_reel = None
                if actor_id:
                    owning_profile_reel = {"__typename": "User", "name": None, "id": actor_id}
                    print(f"üë§ ƒê·∫∑t owning_profile t·ª´ actor_id: {actor_id}")
                else:
                    print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y actor_id trong HTML ƒë·ªÉ ƒë·∫∑t owning_profile cho reel.")

                return post_id, owning_profile_reel, None, final_url
        except Exception:
            pass

        return post_id, owning_profile, post_text, final_url
            
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y HTML source: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def get_page_id_from_html(url, profile_id, cookies=None):
    """
    L·∫•y page_id t·ª´ HTML source c·ªßa trang (view-source)
    S·ª≠ d·ª•ng cookies ƒë·ªÉ m·ªü nh∆∞ tr√¨nh duy·ªát b√¨nh th∆∞·ªùng
    
    Args:
        url (str): URL c·ªßa Facebook page/group
        profile_id (str): Profile ID ƒë·ªÉ l·∫•y cookies
        cookies (str, optional): Cookie string (n·∫øu ƒë√£ c√≥ s·∫µn)
        
    Returns:
        str: page_id ƒë·∫ßu ti√™n t√¨m th·∫•y ho·∫∑c None
    """
    get_cookies_by_profile_id = _import_get_cookies_by_profile_id()

    # ‚úÖ ∆Øu ti√™n tuy·ªát ƒë·ªëi: n·∫øu URL ƒë√£ c√≥ numeric group_id th√¨ tr·∫£ v·ªÅ lu√¥n (·ªïn ƒë·ªãnh nh·∫•t)
    try:
        m_url = re.search(r"/groups/(\d+)", str(url or ""))
        if m_url:
            return m_url.group(1)
    except Exception:
        pass
    
    # L·∫•y cookies n·∫øu ch∆∞a c√≥
    if cookies is None:
        cookies = get_cookies_by_profile_id(profile_id)
        if not cookies:
            print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y cookies t·ª´ profile_id: {profile_id}")
            return None
    
    try:
        # T·∫°o session ƒë·ªÉ qu·∫£n l√Ω cookies t·ªët h∆°n (nh∆∞ tr√¨nh duy·ªát)
        session = requests.Session()
        
        # Parse cookies string th√†nh dict v√† th√™m v√†o session
        if cookies:
            cookies_dict = {}
            for cookie_pair in cookies.split(';'):
                cookie_pair = cookie_pair.strip()
                if '=' in cookie_pair:
                    key, value = cookie_pair.split('=', 1)
                    cookies_dict[key.strip()] = value.strip()
            session.cookies.update(cookies_dict)
        
        # Headers cho GET request (gi·ªëng tr√¨nh duy·ªát, CH·ªà gzip/deflate ƒë·ªÉ tr√°nh l·ªói brotli tr√™n m√°y thi·∫øu th∆∞ vi·ªán)
        get_headers = {
            "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "accept-encoding": "gzip, deflate",
            "accept-language": "en,vi;q=0.9,en-US;q=0.8",
            "referer": "https://www.facebook.com/",
            "sec-ch-ua": '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "same-origin",
            "upgrade-insecure-requests": "1",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"
        }
        
        # L·∫•y HTML source tr·ª±c ti·∫øp (view-source) v·ªõi cookies
        print(f"üåê L·∫•y HTML source (view-source) tr·ª±c ti·∫øp t·ª´: {url}")
        response = session.get(url, headers=get_headers)
        
        if response.status_code != 200:
            return None

        # ‚úÖ N·∫øu Facebook redirect sang URL c√≥ /groups/<id> th√¨ ∆∞u ti√™n l·∫•y lu√¥n t·ª´ response.url
        try:
            m_final = re.search(r"/groups/(\d+)", str(getattr(response, "url", "") or ""))
            if m_final:
                return m_final.group(1)
        except Exception:
            pass
        
        html_content = response.text
        
        # ===== ∆ØU TI√äN L·∫§Y "GROUP ID" (tr√°nh nh·∫∑t nh·∫ßm page_id kh√°c trong HTML) =====
        # 1) C√°c pattern r·∫•t ƒë·∫∑c hi·ªáu cho group
        group_specific_patterns = [
            # page_id_type = group (∆∞u ti√™n)
            r'"page_id"\s*:\s*"(\d+)"\s*,\s*"page_id_type"\s*:\s*"group"',
            r'"page_id_type"\s*:\s*"group"\s*,\s*"page_id"\s*:\s*"(\d+)"',
            # groupID/group_id
            r'"groupID"\s*:\s*"(\d+)"',
            r'"group_id"\s*:\s*"(\d+)"',
        ]
        for pat in group_specific_patterns:
            m = re.search(pat, html_content, flags=re.IGNORECASE)
            if m:
                return m.group(1)

        # 2) N·∫øu HTML c√≥ /groups/<id> th√¨ ∆∞u ti√™n ID xu·∫•t hi·ªán nhi·ªÅu nh·∫•t (tr√°nh d√≠nh 1 ID c·ªë ƒë·ªãnh ·ªü header)
        try:
            group_ids = re.findall(r"/groups/(\d+)", html_content, flags=re.IGNORECASE)
            if group_ids:
                # ch·ªçn ID ph·ªï bi·∫øn nh·∫•t
                freq: dict[str, int] = {}
                for gid in group_ids:
                    freq[gid] = freq.get(gid, 0) + 1
                group_ids_sorted = sorted(freq.items(), key=lambda x: x[1], reverse=True)
                return group_ids_sorted[0][0]
        except Exception:
            pass

        # 3) Fallback cu·ªëi: t√¨m page_id nh∆∞ng ch·ªçn c√°i c√≥ t·∫ßn su·∫•t cao nh·∫•t (ƒë·ª° nh·∫∑t "c√°i ƒë·∫ßu ti√™n")
        try:
            candidates: list[str] = []
            for pat in [
                r'"page_id"\s*:\s*"(\d+)"',
                r'page_id["\']\s*:\s*["\'](\d+)',
                r'page_id=(\d+)',
                r'data-page-id="(\d+)"',
                r'"pageID"\s*:\s*"(\d+)"',
            ]:
                candidates.extend(re.findall(pat, html_content, flags=re.IGNORECASE) or [])
            if candidates:
                freq2: dict[str, int] = {}
                for cid in candidates:
                    freq2[cid] = freq2.get(cid, 0) + 1
                cand_sorted = sorted(freq2.items(), key=lambda x: x[1], reverse=True)
                return cand_sorted[0][0]
        except Exception:
            pass

        return None
            
    except Exception:
        return None


def get_id_from_url(url, profile_id):
    """
    H√†m t·ªïng h·ª£p t·ª± ƒë·ªông ph√°t hi·ªán lo·∫°i URL v√† l·∫•y page_id ho·∫∑c post_id t∆∞∆°ng ·ª©ng
    S·ª≠ d·ª•ng HTML source (view-source) v·ªõi cookies ƒë·ªÉ m·ªü nh∆∞ tr√¨nh duy·ªát b√¨nh th∆∞·ªùng
    
    Logic:
    - N·∫øu URL ch·ª©a "group" ‚Üí l√† group (ch·ªâ l·∫•y page_id)
    - C√≤n l·∫°i t·∫•t c·∫£ ‚Üí l√† post (l·∫•y post_id v√† owning_profile)
    
    Args:
        url (str): URL c·ªßa Facebook (c√≥ th·ªÉ l√† group ho·∫∑c post)
        profile_id (str): Profile ID ƒë·ªÉ l·∫•y cookies
        
    Returns:
        dict: {
            "page_id": str ho·∫∑c None,
            "post_id": str ho·∫∑c None,
            "owning_profile": dict ho·∫∑c None,
            "url_type": str ("group" ho·∫∑c "post")
        }
    """
    get_cookies_by_profile_id = _import_get_cookies_by_profile_id()
    
    # Load cookies m·ªôt l·∫ßn duy nh·∫•t
    cookies = get_cookies_by_profile_id(profile_id)
    
    if not cookies:
        print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y cookies t·ª´ profile_id: {profile_id}")
        return {
            "page_id": None,
            "post_id": None,
            "owning_profile": None,
            "url_type": "post"
        }
    
    url_lower = url.lower()
    result = {
        "page_id": None,
        "post_id": None,
        "owning_profile": None,
        "url_type": "post"  # M·∫∑c ƒë·ªãnh l√† post
    }
    
    # Ph√°t hi·ªán lo·∫°i URL: n·∫øu c√≥ "group" trong URL ‚Üí l√† group
    if "group" in url_lower:
        result["url_type"] = "group"
        page_id = get_page_id_from_html(url, profile_id, cookies)
        result["page_id"] = page_id
        if page_id:
            print(f"page_id: {page_id}")
        return result
    else:
        # T·∫•t c·∫£ c√°c URL kh√°c ƒë·ªÅu l√† post
        result["url_type"] = "post"
        
        # L·∫•y post_id, owning_profile, post_text, final_url t·ª´ HTML source (v·ªõi cookies)
        post_id, owning_profile, post_text, final_url = get_post_id(url, profile_id, cookies)

        result["post_id"] = post_id
        result["owning_profile"] = owning_profile
        result["post_text"] = post_text

        # N·∫øu final_url ch·ª©a 'reel' => x·∫øp lo·∫°i reel, kh√¥ng l·∫•y post_text v√† ƒë·∫∑t owning_profile t·ª´ actor_id
        try:
            if final_url and "reel" in str(final_url).lower():
                result["url_type"] = "reel"
                if owning_profile and isinstance(owning_profile, dict) and owning_profile.get("id"):
                    result["owning_profile"] = owning_profile
                else:
                    result["owning_profile"] = None
                # actor_id n·∫øu c√≥
                if owning_profile and isinstance(owning_profile, dict):
                    result["actor_id"] = owning_profile.get("id")
                result["post_text"] = None
                print(f"üîî X·∫øp lo·∫°i URL l√† 'reel' (final_url: {final_url}) actor_id: {result.get('actor_id')}")
        except Exception:
            pass
        
        # In k·∫øt qu·∫£ cu·ªëi c√πng
        if post_id:
            print(f"post_id: {post_id}")
        
        if owning_profile:
            owning_profile_typename = owning_profile.get("__typename")
            owning_profile_name = owning_profile.get("name")
            owning_profile_id = owning_profile.get("id")
            
            if owning_profile_typename:
                print(f"owning_profile.__typename: {owning_profile_typename}")
            if owning_profile_name:
                print(f"owning_profile.name: {owning_profile_name}")
            if owning_profile_id:
                print(f"owning_profile.id: {owning_profile_id}")

        if post_text:
            preview = post_text[:200] + "..." if len(post_text) > 200 else post_text
            print(f"post_text: {preview}")
        
        return result


if __name__ == "__main__":
    # V√≠ d·ª• s·ª≠ d·ª•ng h√†m get_id_from_url (t·ªïng h·ª£p)
    profile_id = "621e1f5d-0c42-481e-9ddd-7abaafce68ed"
    
    # Test v·ªõi group URL
    # group_url = "https://www.facebook.com/groups/987870664956102/"
    # result = get_id_from_url(group_url, profile_id)
    
    # Test v·ªõi video/post URL
    # url = "https://www.facebook.com/share/p/18AKfiXuZM/"
    url = "https://www.facebook.com/share/r/1EsjjiYvn6/"
    result = get_id_from_url(url, profile_id)
    print("heLLO" ,result)