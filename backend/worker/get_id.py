import requests
import json
import re
from urllib.parse import urlencode, urlparse, parse_qs

# ====== L∆ØU √ù ======
# Cookies v√† payload ƒë∆∞·ª£c l·∫•y t·ª´ cookies.json v√† payload.txt th√¥ng qua profile_id
# cookies.json c√≥ c·∫•u tr√∫c: {"profile_id": {"cookie": "...", "access_token": "..."}}
# S·ª≠ d·ª•ng get_payload.get_payload_by_profile_id(profile_id) ƒë·ªÉ l·∫•y payload
# S·ª≠ d·ª•ng get_payload.get_cookies_by_profile_id(profile_id) ƒë·ªÉ l·∫•y cookie


# ================================
#   H√ÄM G·ªåI API V·ªöI URL VIDEO
# ================================
def get_post_id(video_url, profile_id):
    """
    G·ªçi API v·ªõi URL video ƒë·ªÉ l·∫•y post_id
    
    Args:
        video_url (str): URL c·ªßa video Facebook (v√≠ d·ª•: "https://www.facebook.com/reel/1525194028720314/")
        profile_id (str): Profile ID ƒë·ªÉ l·∫•y cookies v√† payload
        
    Returns:
        str: post_id ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    from get_payload import get_payload_by_profile_id, get_cookies_by_profile_id
    
    # L·∫•y payload v√† cookies t·ª´ profile_id
    payload_dict = get_payload_by_profile_id(profile_id)
    if not payload_dict:
        print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y payload t·ª´ profile_id: {profile_id}")
        return None
    
    cookies = get_cookies_by_profile_id(profile_id)
    if not cookies:
        print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y cookies t·ª´ profile_id: {profile_id}")
        return None
    
    url = "https://www.facebook.com/api/graphql/"
    
    variables = {
        "url": video_url
    }
    
    # S·ª≠ d·ª•ng payload v√† th√™m variables, doc_id
    payload_dict = payload_dict.copy()
    payload_dict["variables"] = json.dumps(variables, ensure_ascii=False)
    payload_dict["doc_id"] = "9840669832713841"
    
    # Chuy·ªÉn dictionary th√†nh form-urlencoded string
    payload = urlencode(payload_dict)
    
    # T·∫°o headers v·ªõi cookies
    headers = {
        "accept": "*/*",
        "accept-encoding": "gzip, deflate, br",
        "accept-language": "en,vi;q=0.9,en-US;q=0.8",
        "content-type": "application/x-www-form-urlencoded",
        "cookie": cookies,
        "origin": "https://www.facebook.com",
        "priority": "u=1, i",
        "referer": "https://www.facebook.com/photo/?fbid=965661036626847&set=a.777896542069965",
        "sec-ch-ua": '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"',
        "sec-fetch-dest": "empty",
        "sec-fetch-mode": "cors",
        "sec-fetch-site": "same-origin",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36",
        "x-asbd-id": "359341",
        "x-fb-friendly-name": "CometUFIReactionsCountTooltipContentQuery",
        "x-fb-lsd": payload_dict.get("lsd", "")
    }
    
    print(f"\nüöÄ G·ªçi API v·ªõi URL video: {video_url}")
    print(f"üìã Variables: {json.dumps(variables, ensure_ascii=False)}")

    # G·ª≠i request
    response = requests.post(url, data=payload, headers=headers)
    
    print(f"üìä Status Code: {response.status_code}")
    
    if response.status_code != 200:
        print(f"‚ùå L·ªói: Status code {response.status_code}")
        print(f"Response text: {response.text[:500]}")
        return None
    
    # Parse v√† l·∫•y post_id
    try:
        response_json = response.json()
        
        # L·∫•y post_id t·ª´ response
        post_id = response_json.get("data", {}).get("xma_preview_data", {}).get("post_id")
        
        if post_id:
            print(f"‚úÖ Post ID: {post_id}")
            return post_id
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y post_id trong response, th·ª≠ fallback sang view-source...")
            # Fallback: T√¨m post_id trong HTML source
            return get_post_id_from_html(video_url, profile_id)
            
    except json.JSONDecodeError as e:
        print(f"‚ùå L·ªói: Response kh√¥ng ph·∫£i JSON h·ª£p l·ªá")
        print(f"Response text (500 k√Ω t·ª± ƒë·∫ßu): {response.text[:500]}")
        print(f"Chi ti·∫øt l·ªói: {e}")
        return None
    except Exception as e:
        print(f"‚ùå L·ªói khi parse response: {e}")
        return None


def get_post_id_from_html(url, profile_id):
    """
    Fallback: L·∫•y post_id t·ª´ HTML source c·ªßa trang (view-source)
    
    Args:
        url (str): URL c·ªßa Facebook post
        profile_id (str): Profile ID ƒë·ªÉ l·∫•y cookies
        
    Returns:
        str: post_id ƒë·∫ßu ti√™n t√¨m th·∫•y ho·∫∑c None
    """
    from get_payload import get_cookies_by_profile_id
    
    # L·∫•y cookies t·ª´ profile_id
    cookies = get_cookies_by_profile_id(profile_id)
    if not cookies:
        print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y cookies t·ª´ profile_id: {profile_id}")
        return None
    
    print(f"\nüîÑ Fallback: ƒêang l·∫•y HTML source (view-source) t·ª´: {url}")
    
    try:
        # Headers cho GET request (kh√°c v·ªõi POST)
        get_headers = {
            "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "accept-encoding": "gzip, deflate, br",
            "accept-language": "en,vi;q=0.9,en-US;q=0.8",
            "cookie": cookies,
            "referer": "https://www.facebook.com/",
            "sec-ch-ua": '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "same-origin",
            "upgrade-insecure-requests": "1",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"
        }
        
        # L·∫•y HTML source v·ªõi cookies
        response = requests.get(url, headers=get_headers)
        
        if response.status_code != 200:
            print(f"‚ùå L·ªói: Status code {response.status_code}")
            return None
        
        html_content = response.text
        print(f"üìÑ ƒê√£ l·∫•y HTML source ({len(html_content)} k√Ω t·ª±)")
        
        # T√¨m post_id b·∫±ng c√°c pattern ph·ªï bi·∫øn
        post_id_patterns = [
            r'"post_id"\s*:\s*"(\d+)"',  # "post_id": "123456789"
            r'"fbid"\s*:\s*"(\d+)"',     # "fbid": "123456789"
            r'"pfbid"\s*:\s*"(\d+)"',    # "pfbid": "123456789"
            r'fbid=(\d+)',                # fbid=123456789
            r'post_id=(\d+)',             # post_id=123456789
            r'/posts/(\d+)',              # /posts/123456789
            r'/photo/\?fbid=(\d+)',       # /photo/?fbid=123456789
            r'"legacy_fbid"\s*:\s*"(\d+)"',  # "legacy_fbid": "123456789"
            r'data-post-id="(\d+)"',      # data-post-id="123456789"
            r'post_id["\']\s*:\s*["\']?(\d+)',  # post_id: "123456789"
        ]
        
        found_ids = []
        for pattern in post_id_patterns:
            matches = re.findall(pattern, html_content, re.IGNORECASE)
            if matches:
                found_ids.extend(matches)
                print(f"   üîç T√¨m th·∫•y {len(matches)} post_id(s) v·ªõi pattern: {pattern[:30]}...")
        
        if found_ids:
            # L·∫•y post_id ƒë·∫ßu ti√™n (th∆∞·ªùng l√† post_id ch√≠nh)
            post_id = found_ids[0]
            print(f"‚úÖ T√¨m th·∫•y post_id t·ª´ HTML: {post_id}")
            print(f"   üìã T·ªïng s·ªë post_id t√¨m th·∫•y: {len(set(found_ids))} (unique)")
            return post_id
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y post_id trong HTML source")
            # L∆∞u HTML ƒë·ªÉ debug
            with open("html_source_debug.html", "w", encoding="utf-8") as f:
                f.write(html_content)
            print(f"   üíæ ƒê√£ l∆∞u HTML source v√†o html_source_debug.html ƒë·ªÉ debug")
            return None
            
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y HTML source: {e}")
        import traceback
        traceback.print_exc()
        return None


def get_page_id_from_html(url, profile_id):
    """
    L·∫•y page_id t·ª´ HTML source c·ªßa trang (view-source)
    
    Args:
        url (str): URL c·ªßa Facebook page/group
        profile_id (str): Profile ID ƒë·ªÉ l·∫•y cookies
        
    Returns:
        str: page_id ƒë·∫ßu ti√™n t√¨m th·∫•y ho·∫∑c None
    """
    from get_payload import get_cookies_by_profile_id
    
    # L·∫•y cookies t·ª´ profile_id
    cookies = get_cookies_by_profile_id(profile_id)
    if not cookies:
        print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y cookies t·ª´ profile_id: {profile_id}")
        return None
    
    print(f"\nüîÑ ƒêang l·∫•y HTML source (view-source) t·ª´: {url}")
    
    try:
        # Headers cho GET request
        get_headers = {
            "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "accept-encoding": "gzip, deflate, br",
            "accept-language": "en,vi;q=0.9,en-US;q=0.8",
            "cookie": cookies,
            "referer": "https://www.facebook.com/",
            "sec-ch-ua": '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "same-origin",
            "upgrade-insecure-requests": "1",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"
        }
        
        # L·∫•y HTML source v·ªõi cookies
        response = requests.get(url, headers=get_headers)
        
        if response.status_code != 200:
            print(f"‚ùå L·ªói: Status code {response.status_code}")
            return None
        
        html_content = response.text
        print(f"üìÑ ƒê√£ l·∫•y HTML source ({len(html_content)} k√Ω t·ª±)")
        
        # T√¨m page_id b·∫±ng c√°c pattern ph·ªï bi·∫øn
        page_id_patterns = [
            r'"page_id"\s*:\s*"(\d+)"',  # "page_id": "987870664956102"
            r'page_id["\']\s*:\s*["\'](\d+)',  # page_id: "987870664956102"
            r'/groups/(\d+)',  # /groups/987870664956102
            r'/pages/(\d+)',  # /pages/987870664956102
            r'page_id=(\d+)',  # page_id=987870664956102
            r'data-page-id="(\d+)"',  # data-page-id="987870664956102"
            r'"pageID"\s*:\s*"(\d+)"',  # "pageID": "987870664956102"
        ]
        
        found_ids = []
        for pattern in page_id_patterns:
            matches = re.findall(pattern, html_content, re.IGNORECASE)
            if matches:
                found_ids.extend(matches)
                print(f"   üîç T√¨m th·∫•y {len(matches)} page_id(s) v·ªõi pattern: {pattern[:50]}...")
        
        # T√¨m trong JSON structure nh∆∞ v√≠ d·ª•: {"987870664956102":{"page_id":"987870664956102","page_id_type":"group"
        # Pattern 1: L·∫•y t·ª´ key c·ªßa JSON object
        json_key_pattern = r'{"(\d+)":\s*{"page_id"\s*:\s*"(\d+)"'
        json_matches = re.findall(json_key_pattern, html_content)
        if json_matches:
            for match in json_matches:
                # L·∫•y c·∫£ key (th∆∞·ªùng l√† page_id) v√† value
                found_ids.append(match[0])  # Key t·ª´ JSON
                found_ids.append(match[1])  # Value t·ª´ page_id field
            print(f"   üîç T√¨m th·∫•y {len(json_matches)} page_id(s) trong JSON structure (key pattern)")
        
        # Pattern 2: T√¨m tr·ª±c ti·∫øp trong JSON v·ªõi page_id_type
        json_with_type_pattern = r'"page_id"\s*:\s*"(\d+)"\s*,\s*"page_id_type"\s*:\s*"[^"]*"'
        json_type_matches = re.findall(json_with_type_pattern, html_content)
        if json_type_matches:
            found_ids.extend(json_type_matches)
            print(f"   üîç T√¨m th·∫•y {len(json_type_matches)} page_id(s) v·ªõi page_id_type")
        
        # Pattern 3: T√¨m trong structure ph·ª©c t·∫°p h∆°n (c√≥ th·ªÉ c√≥ nhi·ªÅu fields gi·ªØa)
        complex_json_pattern = r'{"(\d+)":\s*{[^}]*"page_id"\s*:\s*"(\d+)"'
        complex_matches = re.findall(complex_json_pattern, html_content)
        if complex_matches:
            for match in complex_matches:
                found_ids.append(match[0])  # Key
                found_ids.append(match[1])  # page_id value
            print(f"   üîç T√¨m th·∫•y {len(complex_matches)} page_id(s) trong complex JSON structure")
        
        if found_ids:
            # L·∫•y page_id ƒë·∫ßu ti√™n (th∆∞·ªùng l√† page_id ch√≠nh)
            page_id = found_ids[0]
            print(f"‚úÖ T√¨m th·∫•y page_id t·ª´ HTML: {page_id}")
            print(f"   üìã T·ªïng s·ªë page_id t√¨m th·∫•y: {len(set(found_ids))} (unique)")
            if len(set(found_ids)) > 1:
                print(f"   üìã C√°c page_id t√¨m th·∫•y: {list(set(found_ids))[:5]}")
            return page_id
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y page_id trong HTML source")
            # L∆∞u HTML ƒë·ªÉ debug
            with open("html_source_page_id_debug.html", "w", encoding="utf-8") as f:
                f.write(html_content)
            print(f"   üíæ ƒê√£ l∆∞u HTML source v√†o html_source_page_id_debug.html ƒë·ªÉ debug")
            return None
            
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y HTML source: {e}")
        import traceback
        traceback.print_exc()
        return None


def get_id_from_url(url, profile_id):
    """
    H√†m t·ªïng h·ª£p t·ª± ƒë·ªông ph√°t hi·ªán lo·∫°i URL v√† l·∫•y page_id ho·∫∑c post_id t∆∞∆°ng ·ª©ng
    
    Logic:
    - N·∫øu URL ch·ª©a /groups/ ho·∫∑c /pages/ ‚Üí ch·ªâ l·∫•y page_id
    - N·∫øu URL l√† post/video/reel ‚Üí l·∫•y c·∫£ post_id v√† page_id
    
    Args:
        url (str): URL c·ªßa Facebook (c√≥ th·ªÉ l√† group, page, post, video, reel, ...)
        profile_id (str): Profile ID ƒë·ªÉ l·∫•y cookies v√† payload
        
    Returns:
        dict: {
            "page_id": str ho·∫∑c None,
            "post_id": str ho·∫∑c None,
            "url_type": str ("group", "page", "post", "video", "reel", "unknown")
        }
    """
    url_lower = url.lower()
    result = {
        "page_id": None,
        "post_id": None,
        "url_type": "unknown"
    }
    
    # Ph√°t hi·ªán lo·∫°i URL
    if "/groups/" in url_lower:
        result["url_type"] = "group"
        page_id = get_page_id_from_html(url, profile_id)
        result["page_id"] = page_id
        if page_id:
            print(f"page_id: {page_id}")
        return result
        
    elif "/pages/" in url_lower:
        result["url_type"] = "page"
        page_id = get_page_id_from_html(url, profile_id)
        result["page_id"] = page_id
        if page_id:
            print(f"page_id: {page_id}")
        return result
        
    elif any(keyword in url_lower for keyword in ["/reel/", "/video/", "/watch/", "/share/v/", "/photo/", "/posts/", "/permalink/"]):
        result["url_type"] = "post"
        # L·∫•y post_id
        post_id = get_post_id(url, profile_id)
        result["post_id"] = post_id
        
        # L·∫•y c·∫£ page_id t·ª´ HTML source c·ªßa post
        page_id = get_page_id_from_html(url, profile_id)
        result["page_id"] = page_id
        
        # In k·∫øt qu·∫£
        if post_id:
            print(f"post_id: {post_id}")
        if page_id:
            print(f"page_id: {page_id}")
        return result
        
    else:
        # URL kh√¥ng r√µ r√†ng, th·ª≠ c·∫£ hai
        result["url_type"] = "unknown"
        
        # Th·ª≠ l·∫•y page_id tr∆∞·ªõc
        page_id = get_page_id_from_html(url, profile_id)
        result["page_id"] = page_id
        
        # Th·ª≠ l·∫•y post_id
        post_id = get_post_id(url, profile_id)
        result["post_id"] = post_id
        
        # In k·∫øt qu·∫£
        if page_id:
            print(f"page_id: {page_id}")
        if post_id:
            print(f"post_id: {post_id}")
        
        return result


if __name__ == "__main__":
    # V√≠ d·ª• s·ª≠ d·ª•ng h√†m get_id_from_url (t·ªïng h·ª£p)
    profile_id = "031ca13d-e8fa-400c-a603-df57a2806788"
    
    # Test v·ªõi group URL
    group_url = "https://www.facebook.com/groups/987870664956102/"
    result = get_id_from_url(group_url, profile_id)
    print(f"\nüìä K·∫øt qu·∫£:")
    print(f"   URL Type: {result['url_type']}")
    print(f"   Page ID: {result['page_id']}")
    print(f"   Post ID: {result['post_id']}")
    
    # Test v·ªõi video/post URL
    video_url = "https://www.facebook.com/share/v/17qwV639vQ/?mibextid=wwXIfr"
    result = get_id_from_url(video_url, profile_id)
    print(f"\nüìä K·∫øt qu·∫£:")
    print(f"   URL Type: {result['url_type']}")
    print(f"   Page ID: {result['page_id']}")
    print(f"   Post ID: {result['post_id']}")