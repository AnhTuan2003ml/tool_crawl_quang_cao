import requests
import json
import re
from urllib.parse import urlencode, urlparse, parse_qs

# ====== ƒê·ªåC COOKIE T·ª™ FILE ======
COOKIE_FILE = "backend/config/cookies.txt"
try:
    with open(COOKIE_FILE, "r", encoding="utf-8") as f:
        COOKIE = f.read().strip()
    # Lo·∫°i b·ªè k√Ω t·ª± xu·ªëng d√≤ng v√† kho·∫£ng tr·∫Øng th·ª´a
    COOKIE = " ".join(COOKIE.split())
    print(f"‚úÖ ƒê√£ ƒë·ªçc cookie t·ª´ {COOKIE_FILE}")
except FileNotFoundError:
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {COOKIE_FILE}!")
    print(f"Vui l√≤ng t·∫°o file {COOKIE_FILE} v√† th√™m cookie v√†o ƒë√≥.")
    exit(1)
except Exception as e:
    print(f"‚ùå L·ªói khi ƒë·ªçc {COOKIE_FILE}: {e}")
    exit(1)

# ====== HEADERS T·ª™ REQUEST ======
HEADERS = {
    "accept": "*/*",
    "accept-encoding": "gzip, deflate, br",  # Lo·∫°i b·ªè zstd v√¨ requests kh√¥ng h·ªó tr·ª£ t·ª± ƒë·ªông
    "accept-language": "en,vi;q=0.9,en-US;q=0.8",
    "content-type": "application/x-www-form-urlencoded",
    "cookie": COOKIE,
    "origin": "https://www.facebook.com",
    "priority": "u=1, i",
    "referer": "https://www.facebook.com/photo/?fbid=965661036626847&set=a.777896542069965",
    "sec-ch-ua": '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
    "sec-ch-ua-mobile": "?0",
    "sec-ch-ua-platform": '"Windows"',
    "sec-fetch-dest": "empty",
    "sec-fetch-mode": "cors",
    "sec-fetch-site": "same-origin",
    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36",
    "x-asbd-id": "359341",
    "x-fb-friendly-name": "CometUFIReactionsCountTooltipContentQuery",
    "x-fb-lsd": "OdWgrzyRzfrz5zMIFQOfKy"
}

SESSION = requests.Session()
SESSION.headers.update(HEADERS)

# ====== ƒê·ªåC PAYLOAD T·ª™ FILE ======
PAYLOAD_FILE = "backend/config/payload.txt"
def load_payload_from_file():
    """
    ƒê·ªçc payload t·ª´ file payload.txt v√† tr·∫£ v·ªÅ dictionary
    
    Returns:
        dict: Payload dictionary t·ª´ file
    """
    try:
        with open(PAYLOAD_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
        
        # Parse t·ª´ng d√≤ng key: value
        payload_dict = {}
        for line in content.split('\n'):
            line = line.strip()
            if not line or not ':' in line:
                continue
            
            # T√°ch key v√† value
            parts = line.split(':', 1)
            if len(parts) == 2:
                # Lo·∫°i b·ªè t·∫•t c·∫£ d·∫•u ngo·∫∑c k√©p, d·∫•u nh√°y ƒë∆°n v√† d·∫•u ph·∫©y
                key = parts[0].strip().replace('"', '').replace("'", '')
                value = parts[1].strip().replace('"', '').replace("'", '').rstrip(',').strip()
                if key and value:  # Ch·ªâ th√™m n·∫øu c·∫£ key v√† value ƒë·ªÅu kh√¥ng r·ªóng
                    payload_dict[key] = value
        
        print(f"‚úÖ ƒê√£ ƒë·ªçc payload t·ª´ {PAYLOAD_FILE}")
        return payload_dict
    except FileNotFoundError:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {PAYLOAD_FILE}!")
        print(f"Vui l√≤ng t·∫°o file {PAYLOAD_FILE} v√† th√™m payload v√†o ƒë√≥.")
        exit(1)
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc {PAYLOAD_FILE}: {e}")
        exit(1)

# Load payload m·ªôt l·∫ßn khi import module
BASE_PAYLOAD = load_payload_from_file()


# ================================
#   H√ÄM G·ªåI API V·ªöI URL VIDEO
# ================================
def get_post_id(video_url):
    """
    G·ªçi API v·ªõi URL video ƒë·ªÉ l·∫•y post_id
    
    Args:
        video_url (str): URL c·ªßa video Facebook (v√≠ d·ª•: "https://www.facebook.com/reel/1525194028720314/")
        
    Returns:
        str: post_id ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    url = "https://www.facebook.com/api/graphql/"
    
    variables = {
        "url": video_url
    }
    
    # ƒê·ªçc payload t·ª´ file v√† th√™m variables, doc_id
    payload_dict = BASE_PAYLOAD.copy()
    payload_dict["variables"] = json.dumps(variables, ensure_ascii=False)
    payload_dict["doc_id"] = "9840669832713841"
    
    # Chuy·ªÉn dictionary th√†nh form-urlencoded string
    payload = urlencode(payload_dict)
    
    print(f"\nüöÄ G·ªçi API v·ªõi URL video: {video_url}")
    print(f"üìã Variables: {json.dumps(variables, ensure_ascii=False)}")

    # G·ª≠i request
    response = SESSION.post(url, data=payload)
    
    print(f"üìä Status Code: {response.status_code}")
    
    if response.status_code != 200:
        print(f"‚ùå L·ªói: Status code {response.status_code}")
        print(f"Response text: {response.text[:500]}")
        return None
    
    # Parse v√† l·∫•y post_id
    try:
        response_json = response.json()
        
        # L·∫•y post_id t·ª´ response
        post_id = response_json.get("data", {}).get("xma_preview_data", {}).get("post_id")
        
        if post_id:
            print(f"‚úÖ Post ID: {post_id}")
            return post_id
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y post_id trong response, th·ª≠ fallback sang view-source...")
            # Fallback: T√¨m post_id trong HTML source
            return get_post_id_from_html(video_url)
            
    except json.JSONDecodeError as e:
        print(f"‚ùå L·ªói: Response kh√¥ng ph·∫£i JSON h·ª£p l·ªá")
        print(f"Response text (500 k√Ω t·ª± ƒë·∫ßu): {response.text[:500]}")
        print(f"Chi ti·∫øt l·ªói: {e}")
        return None
    except Exception as e:
        print(f"‚ùå L·ªói khi parse response: {e}")
        return None


def get_post_id_from_html(url):
    """
    Fallback: L·∫•y post_id t·ª´ HTML source c·ªßa trang (view-source)
    
    Args:
        url (str): URL c·ªßa Facebook post
        
    Returns:
        str: post_id ƒë·∫ßu ti√™n t√¨m th·∫•y ho·∫∑c None
    """
    print(f"\nüîÑ Fallback: ƒêang l·∫•y HTML source (view-source) t·ª´: {url}")
    
    try:
        # Headers cho GET request (kh√°c v·ªõi POST)
        get_headers = {
            "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "accept-encoding": "gzip, deflate, br",
            "accept-language": "en,vi;q=0.9,en-US;q=0.8",
            "cookie": COOKIE,
            "referer": "https://www.facebook.com/",
            "sec-ch-ua": '"Google Chrome";v="143", "Chromium";v="143", "Not A(Brand";v="24"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "same-origin",
            "upgrade-insecure-requests": "1",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36"
        }
        
        # L·∫•y HTML source v·ªõi cookies
        response = SESSION.get(url, headers=get_headers)
        
        if response.status_code != 200:
            print(f"‚ùå L·ªói: Status code {response.status_code}")
            return None
        
        html_content = response.text
        print(f"üìÑ ƒê√£ l·∫•y HTML source ({len(html_content)} k√Ω t·ª±)")
        
        # T√¨m post_id b·∫±ng c√°c pattern ph·ªï bi·∫øn
        post_id_patterns = [
            r'"post_id"\s*:\s*"(\d+)"',  # "post_id": "123456789"
            r'"fbid"\s*:\s*"(\d+)"',     # "fbid": "123456789"
            r'"pfbid"\s*:\s*"(\d+)"',    # "pfbid": "123456789"
            r'fbid=(\d+)',                # fbid=123456789
            r'post_id=(\d+)',             # post_id=123456789
            r'/posts/(\d+)',              # /posts/123456789
            r'/photo/\?fbid=(\d+)',       # /photo/?fbid=123456789
            r'"legacy_fbid"\s*:\s*"(\d+)"',  # "legacy_fbid": "123456789"
            r'data-post-id="(\d+)"',      # data-post-id="123456789"
            r'post_id["\']\s*:\s*["\']?(\d+)',  # post_id: "123456789"
        ]
        
        found_ids = []
        for pattern in post_id_patterns:
            matches = re.findall(pattern, html_content, re.IGNORECASE)
            if matches:
                found_ids.extend(matches)
                print(f"   üîç T√¨m th·∫•y {len(matches)} post_id(s) v·ªõi pattern: {pattern[:30]}...")
        
        if found_ids:
            # L·∫•y post_id ƒë·∫ßu ti√™n (th∆∞·ªùng l√† post_id ch√≠nh)
            post_id = found_ids[0]
            print(f"‚úÖ T√¨m th·∫•y post_id t·ª´ HTML: {post_id}")
            print(f"   üìã T·ªïng s·ªë post_id t√¨m th·∫•y: {len(set(found_ids))} (unique)")
            return post_id
        else:
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y post_id trong HTML source")
            # L∆∞u HTML ƒë·ªÉ debug
            with open("html_source_debug.html", "w", encoding="utf-8") as f:
                f.write(html_content)
            print(f"   üíæ ƒê√£ l∆∞u HTML source v√†o html_source_debug.html ƒë·ªÉ debug")
            return None
            
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y HTML source: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # V√≠ d·ª• s·ª≠ d·ª•ng h√†m get_post_id
    video_url = "https://www.facebook.com/share/p/1BvHoT8PUU/"
    post_id = get_post_id(video_url)
    if post_id:
        print(f"\n‚úÖ Post ID ƒë√£ l·∫•y ƒë∆∞·ª£c: {post_id}")

